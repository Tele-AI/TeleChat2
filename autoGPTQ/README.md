# GPTQ
ä¸ºäº†é™ä½æ˜¾å­˜æ¶ˆè€—å¹¶æå‡æ¨ç†é€Ÿåº¦ï¼Œå¯ä»¥ä½¿ç”¨ GPTQ ç®—æ³•å°† TeleChat æ¨¡å‹çš„æƒé‡é‡åŒ–ä¸º  `8-bit`ç”šè‡³`2-bit` ã€‚æœ¬æ–‡æ¡£å°†è¯¦ç»†ä»‹ç»è¯¥è¿‡ç¨‹ï¼Œå¹¶åˆ©ç”¨ vLLM åº“è¿›è¡Œæ¨ç†ã€‚  

æœ¬æ–‡æ¡£ä»¥`TeleChat2-7B-32K`ä¸ºä¾‹ï¼Œä¸‹é¢æ˜¯æ¨¡å‹çš„ä¸¤ä¸ªä¸‹è½½é“¾æ¥ï¼Œå‡è®¾æ¨¡å‹å·²ä¸‹è½½åˆ°æœ¬åœ°ç›®å½• **/workspace/TeleChat2-7B**

- huggingface [Tele-AI/TeleChat2-7B-32K](https://huggingface.co/Tele-AI/TeleChat2-7B-32K)
- é­”å¡”ç¤¾åŒº [Tele-AI/TeleChat2-7B-32K](https://www.modelscope.cn/models/TeleAI/TeleChat2-7B-32K/summary)

### 1. ä¾èµ–å®‰è£…

``` shell
pip install gptqmodel --no-build-isolation
pip install transformers
pip install accelerate==0.34.2
pip install flash-attn==2.6.3
```
å¦‚æœéœ€è¦ä½¿ç”¨VLLMæ¨ç†ï¼Œè¿˜éœ€è¦å®‰è£…vllm

```shell
pip install vllm==0.6.5
```
### 2. é‡åŒ–æ¨¡å‹

è¦å¯¹ **TeleChat2-7B-32K** æ¨¡å‹è¿›è¡Œé‡åŒ–ï¼Œéœ€è¦å‡†å¤‡ä¸€ä¸ª **æ ¡å‡†æ•°æ®é›†**ï¼Œæ ¼å¼ä¸º **TXT æ–‡ä»¶**ï¼Œå…¶ä¸­æ¯è¡Œä»£è¡¨ä¸€æ¡æ ¡å‡†æ•°æ®ã€‚ç„¶åè¿è¡Œå½“å‰ç›®å½•ä¸‹çš„ `quantize.py` è„šæœ¬ã€‚
```python
python3 quantize.py --trust_remote_code /workspace/TeleChat2-7B /path/to/calib_dataset.txt /workspace/TeleChat2-7B-GPTQ
```

### 3. æ›´æ–°vllmçš„ä»£ç 
telechatä¸­çš„æŸäº›å±‚æ— æ³•ä½¿ç”¨gptqé‡åŒ–ï¼Œä½†æ˜¯ç›®å‰vllmä¸­å…³äºgptqéƒ¨åˆ†çš„ä»£ç ä¸æ”¯æŒéƒ¨åˆ†å±‚é‡åŒ–ï¼Œæ‰€ä»¥éœ€è¦å¯¹vllmä¸­çš„ä»£ç è¿›è¡Œæ›´æ”¹ï¼Œæ­¤æ–‡æ¡£ä½¿ç”¨çš„vllmç‰ˆæœ¬æ˜¯v0.6.5ï¼Œå…¶ä»–ç‰ˆæœ¬è¯·æ ¹æ®æ ·ä¾‹ä¿®æ”¹ä»£ç ã€‚  

ğŸ˜ƒ **ç¡®å®švllmç‰ˆæœ¬ç­‰äº0.6.5**  
åœ¨å½“å‰ç›®å½•æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ›´æ–°vllmå·²å®‰è£…çš„ä»£ç 

```shell
bash apply_path.sh
```
å¦‚æœè¾“å‡ºsuccessï¼Œè¯´æ˜æ‰§è¡ŒæˆåŠŸ  

### 4. ä½¿ç”¨vllmåº“æ¥æ¨ç†é‡åŒ–åçš„æ¨¡å‹
```shell
vllm serve /workspace/TeleChat2-7B-GPTQ --served-model-name telechat-gptq --dtype float16 --max_model_len 4096 --trust_remote_code 
```
ç­‰æ¨¡å‹å¯åŠ¨åï¼Œå¯ä»¥ä½¿ç”¨curlå‘½ä»¤å‘é€è¯·æ±‚
```shell
curl http://localhost:8000/v1/chat/completions -H "Content-Type: application/json" -d '{
  "model": "telechat-gptq",
  "messages": [
    {"role": "user", "content": "ç”ŸæŠ½ä¸è€æŠ½çš„åŒºåˆ«ï¼Ÿ"}
  ],
  "temperature": 1.0,
  "top_p": 1.0,
  "repetition_penalty": 1.03,
  "max_tokens": 512
}'
```
æˆ–è€…ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨Openaiæä¾›çš„apiæ¥å‘é€è¯·æ±‚
```python
from openai import OpenAI

openai_api_key = "xxx"
openai_api_base = "http://localhost:8000/v1"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

resp = client.chat.completions.create(
    model="telechat-gptq",
    messages=[
        {"role": "user", "content": "ç”ŸæŠ½ä¸è€æŠ½çš„åŒºåˆ«ï¼Ÿ"}
    ],
    temperature=1.0,
    top_p=1.0,
    max_tokens=512,
    extra_body={
        "repetition_penalty": 1.03,
    },
)
print("response:", resp)
```