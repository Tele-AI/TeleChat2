# AWQ
ä¸ºäº†é™ä½æ˜¾å­˜æ¶ˆè€—å¹¶æå‡æ¨ç†é€Ÿåº¦ï¼Œå¯ä»¥ä½¿ç”¨ AWQ ç®—æ³•å°† TeleChat æ¨¡å‹çš„æƒé‡é‡åŒ–è‡³  `4-bit` ã€‚æœ¬æ–‡æ¡£å°†è¯¦ç»†ä»‹ç»è¯¥è¿‡ç¨‹ï¼Œå¹¶åˆ©ç”¨ Transformers å’Œ vLLM åº“è¿›è¡Œæ¨ç†ã€‚  

æœ¬æ–‡æ¡£ä½¿ç”¨`TeleChat2-7B-32K`ä¸ºä¾‹ï¼Œä»¥ä¸‹ä¸ºä¸‹è½½é“¾æ¥ï¼Œå‡è®¾æ¨¡å‹å·²ä¸‹è½½åˆ°æœ¬åœ°ç›®å½• **/workspace/TeleChat2-7B**

- huggingface [Tele-AI/TeleChat2-7B-32K](https://huggingface.co/Tele-AI/TeleChat2-7B-32K)
- é­”å¡”ç¤¾åŒº [Tele-AI/TeleChat2-7B-32K](https://www.modelscope.cn/models/TeleAI/TeleChat2-7B-32K/summary)

### 1. ä¾èµ–å®‰è£…

``` shell
pip install autoawq
pip install transformers
pip install accelerate==0.34.2
pip install flash-attn==2.6.3
```
å¦‚æœéœ€è¦ä½¿ç”¨VLLMæ¨ç†ï¼Œè¿˜éœ€è¦å®‰è£…vllm

```shell
pip install vllm==0.6.5
```
### 2. å‡†å¤‡é‡åŒ–æ¨¡å‹

è¦å¯¹ **TeleChat2-7B-32K** æ¨¡å‹è¿›è¡Œé‡åŒ–ï¼Œè¯·è¿è¡Œå½“å‰ç›®å½•ä¸‹çš„ `quantize.py` è„šæœ¬ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œéœ€è¦å‡†å¤‡ä¸€ä¸ª **æ ¡å‡†æ•°æ®é›†**ï¼Œæ ¼å¼ä¸º **TXT æ–‡ä»¶**ï¼Œå…¶ä¸­æ¯è¡Œä»£è¡¨ä¸€æ¡æ ¡å‡†æ•°æ®ã€‚
```python
python3 quantize.py --trust_remote_code /workspace/TeleChat2-7B /path/to/calib_dataset.txt /workspace/TeleChat2-7B-AWQ
```

### 3. ä½¿ç”¨vllmåº“æ¥æ¨ç†é‡åŒ–åçš„æ¨¡å‹

ğŸ˜ƒ **ç¡®å®švllmç‰ˆæœ¬å¤§äºç­‰äº0.6.5**
```shell
vllm serve /workspace/TeleChat2-7B-AWQ --served-model-name telechat-awq --dtype float16 --max_model_len 4096 --trust_remote_code 
```
ç­‰æ¨¡å‹å¯åŠ¨åï¼Œå¯ä»¥ä½¿ç”¨curlå‘½ä»¤å‘é€è¯·æ±‚
```shell
curl http://localhost:8000/v1/chat/completions -H "Content-Type: application/json" -d '{
  "model": "telechat-awq",
  "messages": [
    {"role": "user", "content": "ç”ŸæŠ½ä¸è€æŠ½çš„åŒºåˆ«ï¼Ÿ"}
  ],
  "temperature": 1.0,
  "top_p": 1.0,
  "repetition_penalty": 1.03,
  "max_tokens": 512
}'
```
æˆ–è€…ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨Openaiæä¾›çš„apiæ¥å‘é€è¯·æ±‚
```python
from openai import OpenAI

openai_api_key = "xxx"
openai_api_base = "http://localhost:8000/v1"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

resp = client.chat.completions.create(
    model="telechat-awq",
    messages=[
        {"role": "user", "content": "ç”ŸæŠ½ä¸è€æŠ½çš„åŒºåˆ«ï¼Ÿ"}
    ],
    temperature=1.0,
    top_p=1.0,
    max_tokens=512,
    extra_body={
        "repetition_penalty": 1.03,
    },
)
print("response:", resp)
```